{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as palm\n",
    "\n",
    "palm.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm\n",
    "\n",
    "import chromadb\n",
    "from chromadb.api.types import Documents, Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader  #load pdf\n",
    "from langchain.indexes import VectorstoreIndexCreator #vectorize db index with chromadb\n",
    "from langchain.text_splitter import CharacterTextSplitter #text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cold.\n"
     ]
    }
   ],
   "source": [
    "response = palm.generate_text(prompt=\"The opposite of hot is\")\n",
    "print(response.result)  # cold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new conversation\n",
    "response = palm.chat(messages='Hello')\n",
    "\n",
    "# Last contains the model's response:\n",
    "response.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n"
     ]
    }
   ],
   "source": [
    "for model in palm.list_models():\n",
    "  if 'embedText' in model.supported_generation_methods:\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [m for m in palm.list_models() if 'embedText' in m.supported_generation_methods]\n",
    "\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's load the pdf book \n",
    "pdf_loader = PyPDFLoader('Books/DLCV/DLCV.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Book = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in Book:\n",
    "    text.append(i.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MANNINGMohamed Elgendy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deep Learning for\\nVision Systems\\nMOHAMED  EL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For online information and ordering of this an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To my mom, Huda, who taught me perseverance a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>INDEX 455\\nperformance metrics (continued)\\npr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>INDEX 456\\nscipy.optimize.fmin_l_bfgs_b method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>INDEX 457\\ntraining (continued)\\npreparing dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>INDEX 458\\nvisual embeddings (continued)\\nmini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Mohamed Elgendy\\nISBN: 978-1-61729-619-2\\nHow ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text\n",
       "0                               MANNINGMohamed Elgendy\n",
       "1    Deep Learning for\\nVision Systems\\nMOHAMED  EL...\n",
       "2    For online information and ordering of this an...\n",
       "3     To my mom, Huda, who taught me perseverance a...\n",
       "4                                                     \n",
       "..                                                 ...\n",
       "475  INDEX 455\\nperformance metrics (continued)\\npr...\n",
       "476  INDEX 456\\nscipy.optimize.fmin_l_bfgs_b method...\n",
       "477  INDEX 457\\ntraining (continued)\\npreparing dat...\n",
       "478  INDEX 458\\nvisual embeddings (continued)\\nmini...\n",
       "479  Mohamed Elgendy\\nISBN: 978-1-61729-619-2\\nHow ...\n",
       "\n",
       "[480 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(text)\n",
    "df.columns = ['Text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MANNINGMohamed Elgendy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deep Learning for\\nVision Systems\\nMOHAMED  EL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For online information and ordering of this an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To my mom, Huda, who taught me perseverance a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vcontents\\npreface xiii\\nacknowledgments xv\\na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CONTENTS vi\\n1.5 Image preprocessing 23\\nConve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CONTENTS vii\\n3 Convolutional neural networks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CONTENTS viii\\n4.5 Improving the network and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CONTENTS ix\\n5.5 Inception and GoogLeNet 217\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CONTENTS x\\n7.2 Region-based convolutional neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CONTENTS xi\\n9.2 DeepDream 384\\nHow the DeepDr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xiiipreface\\nTwo years ago, I decided to write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PREFACE xiv\\n As a beginner, I searched but co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xvacknowledgments\\nThis book was a lot of work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xviabout this book\\nWho should read this book\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ABOUT THIS BOOK xvii\\ndoesn’t interrupt your f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ABOUT THIS BOOK xviii\\naccess the forum, go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xixabout the author\\nMohamed Elgendy  is the v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text\n",
       "0                              MANNINGMohamed Elgendy\n",
       "1   Deep Learning for\\nVision Systems\\nMOHAMED  EL...\n",
       "2   For online information and ordering of this an...\n",
       "3    To my mom, Huda, who taught me perseverance a...\n",
       "4                                                    \n",
       "5   vcontents\\npreface xiii\\nacknowledgments xv\\na...\n",
       "6   CONTENTS vi\\n1.5 Image preprocessing 23\\nConve...\n",
       "7   CONTENTS vii\\n3 Convolutional neural networks ...\n",
       "8   CONTENTS viii\\n4.5 Improving the network and t...\n",
       "9   CONTENTS ix\\n5.5 Inception and GoogLeNet 217\\n...\n",
       "10  CONTENTS x\\n7.2 Region-based convolutional neu...\n",
       "11  CONTENTS xi\\n9.2 DeepDream 384\\nHow the DeepDr...\n",
       "12                                                   \n",
       "13  xiiipreface\\nTwo years ago, I decided to write...\n",
       "14  PREFACE xiv\\n As a beginner, I searched but co...\n",
       "15  xvacknowledgments\\nThis book was a lot of work...\n",
       "16  xviabout this book\\nWho should read this book\\...\n",
       "17  ABOUT THIS BOOK xvii\\ndoesn’t interrupt your f...\n",
       "18  ABOUT THIS BOOK xviii\\naccess the forum, go to...\n",
       "19  xixabout the author\\nMohamed Elgendy  is the v..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get len of chars in the Text\n",
    "\n",
    "df['chars_len'] = df['Text'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chars_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1939.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>659.753035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1520.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1972.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3421.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         chars_len\n",
       "count   480.000000\n",
       "mean   1939.004167\n",
       "std     659.753035\n",
       "min       0.000000\n",
       "25%    1520.250000\n",
       "50%    1972.500000\n",
       "75%    2413.000000\n",
       "max    3421.000000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Rows which len less that 10\n",
    "\n",
    "df = df[df['chars_len'] > 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vcontents\\npreface xiii\\nacknowledgments xv\\nabout this book xvi\\nabout the author xix\\nabout the cover illustration xx\\nPART 1DEEP LEARNING  FOUNDATION ............................. 1\\n1 Welcome to computer vision 3\\n1.1 Computer vision 4\\nWhat is visual perception? 5■Vision systems 5\\nSensing devices 7■Interpreting devices 8\\n1.2 Applications of computer vision 10\\nImage classification 10■Object detection and localization 12\\nGenerating art (style transfer) 12■Creating images 13\\nFace recognition 15■Image recommendation system 15\\n1.3 Computer vision pipeline: The big picture 17\\n1.4 Image input 19\\nImage as functions 19■How computers see images 21\\nColor images 21'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the text at the index = 4\n",
    "df['Text'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [m for m in palm.list_models() if 'embedText' in m.supported_generation_methods]\n",
    "emb_model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df to csv file\n",
    "df.to_csv('Embeddings/DLCV.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is loss function ?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_best_passage(query, dataframe):\n",
    "    \"\"\"\n",
    "    Compute the distances between the query and each document in the dataframe\n",
    "    using the dot product.\n",
    "    \"\"\"\n",
    "    query_embedding = palm.generate_embeddings(model=emb_model, text=query)\n",
    "    dot_products = np.dot(np.stack(dataframe['Embeddings']), query_embedding['embedding'])\n",
    "    idx = np.argmax(dot_products)\n",
    "    return dataframe.iloc[idx]['Text'] # Return text from index with max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (474,) and (768,) not aligned: 474 (dim 0) != 768 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m passage \u001b[39m=\u001b[39m find_best_passage(query, df)\n\u001b[1;32m      2\u001b[0m passage\n",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m, in \u001b[0;36mfind_best_passage\u001b[0;34m(query, dataframe)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mCompute the distances between the query and each document in the dataframe\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39musing the dot product.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m query_embedding \u001b[39m=\u001b[39m palm\u001b[39m.\u001b[39mgenerate_embeddings(model\u001b[39m=\u001b[39memb_model, text\u001b[39m=\u001b[39mquery)\n\u001b[0;32m----> 9\u001b[0m dot_products \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(np\u001b[39m.\u001b[39;49mstack(dataframe[\u001b[39m'\u001b[39;49m\u001b[39mEmbeddings\u001b[39;49m\u001b[39m'\u001b[39;49m]), query_embedding[\u001b[39m'\u001b[39;49m\u001b[39membedding\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     10\u001b[0m idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(dot_products)\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m dataframe\u001b[39m.\u001b[39miloc[idx][\u001b[39m'\u001b[39m\u001b[39mText\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (474,) and (768,) not aligned: 474 (dim 0) != 768 (dim 0)"
     ]
    }
   ],
   "source": [
    "passage = find_best_passage(query, df)\n",
    "passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def make_prompt(query, relevant_passage):\n",
    "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "  prompt = textwrap.dedent(\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "  Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "  However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "  strike a friendly and converstional tone and gave example. \\\n",
    "  If the passage is irrelevant to the answer, you may ignore it.\n",
    "  QUESTION: '{query}'\n",
    "  PASSAGE: '{relevant_passage}'\n",
    "\n",
    "    ANSWER:\n",
    "  \"\"\").format(query=query, relevant_passage=escaped)\n",
    "\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful and informative bot that answers questions using text from the reference passage included below.   Be sure to respond in a complete sentence, being comprehensive, including all relevant background information.   However, you are talking to a non-technical audience, so be sure to break down complicated concepts and   strike a friendly and converstional tone and gave example.   If the passage is irrelevant to the answer, you may ignore it.\n",
      "  QUESTION: 'What is loss function ?'\n",
      "  PASSAGE: '69 Error functions 2.5.1 What is the error function?  The error function  is a measure of how “wrong” the neural network prediction is with respect to the expected output (the label). It quantifies how far we are from the cor- rect solution. For example, if we have a high loss, then our model is not doing a good job. The smaller the loss, the better the job the model is doing. The larger the loss, the more our model needs to be trained to increase its accuracy. 2.5.2 Why do we need an error function? Calculating error is an optimization problem, something all machine learning engi- neers love (mathematicians, too). Optimization problems focus on defining an error function and trying to optimize its parameters to get the minimum error (more on optimization in the next section). But for now, know that, in general, when we are working on an optimization problem, if we are able to define the error function for the problem, we have a very good shot at solving it by running optimization algo- rithms to minimize the error function.  In optimization problems, our ultimate goal is to find the optimum variables (weights) that would minimize the error function as much as we can. If we don’t know how far from the target we are, how will we know what to change in the next iteration? The process of minimizing this error is called error function optimization . We will review several optimization methods in the next section. But for now, all we need to know from the error function is how far we are from the correct prediction, or how much we missed the desired degree of performance.  2.5.3 Error is always positive Consider this scenario: suppose we have two data points that we are trying to get our network to predict correctly. If the first gives an error of 10 and the second gives an error of –10, then our average error is zero! This is misleading because “error = 0” means our network is producing perfect predictions, when, in fact, it missed by 10 twice. We don’t want that. We want the error of each prediction to be positive, so the errors don’t cancel each other when we take the average error. Think of an archer aiming at a target and missing by 1 inch. We are not really concerned about which direction they missed; all we need to know is how far each shot is from the target.  A visualization of loss functions of two separate models plotted over time is shown in figure 2.24. You can see that model #1 is doing a better job of minimizing error, whereas model #2 starts off better until epoch 6 and then plateaus.  Different loss functions will give different errors for the same prediction, and thus have a considerable effect on the performance of the model. A thorough discussion of loss functions is outside the scope of this book. Instead, we will focus on the two most commonly used loss functions: mean squared error (and its variations), usually used for regression problems, and cross-entropy, used for classification problems. '\n",
      "\n",
      "    ANSWER:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = make_prompt(query, passage)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "\n",
    "text_model = text_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.5\n",
    "answer = palm.generate_text(prompt=prompt,\n",
    "                            model=text_model,\n",
    "                            candidate_count=3,\n",
    "                            temperature=temperature,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate 0: The error function is a measure of how \"wrong\" the neural network prediction is with respect to the expected output (the label). It quantifies how far we are from the correct solution.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, candidate in enumerate(answer.candidates):\n",
    "  print(f\"Candidate {i}: {candidate['output']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A loss function is like a grade you get on a test. It tells you how well you did, and it can help you figure out where you need to improve.\n",
      "\n",
      "For example, let's say you're learning to identify different types of animals. You might be given a picture of a dog, and you have to guess whether it's a golden retriever or a Labrador retriever. If you guess correctly, you get a good grade. But if you guess wrong, you get a bad grade.\n",
      "\n",
      "The loss function works the same way. It tells you how far off your prediction was from the actual output. If your prediction is close to the output, you get a good grade. But if your prediction is far off, you get a bad grade.\n",
      "\n",
      "The loss function is important because it helps you track your progress and see where you need to improve. If you're getting a lot of bad grades, it means you need to study more or practice more. And if you're getting a lot of good grades, it means you're doing a great job and you can keep up the good work.\n"
     ]
    }
   ],
   "source": [
    "response = palm.generate_text(prompt='''\n",
    "rewrite this and gave an example for a kid to help him under stand it (Candidate 0: A loss function is a measure of how “wrong” the neural network prediction is with respect to the expected output (the label).)\n",
    "''')\n",
    "print(response.result)  # cold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## **Loss Function**\n",
      "\n",
      "A loss function is like a grade you get on a test. It tells you how well you did, and it can help you figure out where you need to improve.\n",
      "\n",
      "For example, let's say you're learning to identify different types of animals. You might be given a picture of a dog, and you have to guess whether it's a golden retriever or a Labrador retriever. If you guess correctly, you get a good grade. But if you guess wrong, you get a bad grade.\n",
      "\n",
      "The loss function works the same way. It tells you how far off your prediction was from the actual output. If your prediction is close to the output, you get a good grade. But if your prediction is far off, you get a bad grade.\n",
      "\n",
      "The loss function is important because it helps you track your progress and see where you need to improve. If you're getting a lot of bad grades, it means you need to study more or practice more. And if you're getting a lot of good grades, it means you're doing a great job and you can keep up the good work.\n",
      "\n",
      "Here is a more mathematical definition of a loss function:\n",
      "\n",
      "```\n",
      "L(y, \\hat{y}) = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
      "```\n",
      "\n",
      "where $y$ is the actual output, $\\hat{y}$ is the predicted output, and $n$ is the number of data points.\n",
      "\n",
      "The loss function is a measure of how far off the predicted output is from the actual output. The smaller the loss function, the better the prediction.\n",
      "\n",
      "Loss functions are used in machine learning to train models. By minimizing the loss function, we can train models to make better predictions.\n"
     ]
    }
   ],
   "source": [
    "response = palm.generate_text(prompt='''\n",
    "use this to make a mark down as presntion to explain for childernes (A loss function is like a grade you get on a test. It tells you how well you did, and it can help you figure out where you need to improve.\n",
    "\n",
    "For example, let's say you're learning to identify different types of animals. You might be given a picture of a dog, and you have to guess whether it's a golden retriever or a Labrador retriever. If you guess correctly, you get a good grade. But if you guess wrong, you get a bad grade.\n",
    "\n",
    "The loss function works the same way. It tells you how far off your prediction was from the actual output. If your prediction is close to the output, you get a good grade. But if your prediction is far off, you get a bad grade.\n",
    "\n",
    "The loss function is important because it helps you track your progress and see where you need to improve. If you're getting a lot of bad grades, it means you need to study more or practice more. And if you're getting a lot of good grades, it means you're doing a great job and you can keep up the good work.)\n",
    "''')\n",
    "print(response.result)  # cold."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loss Function**\n",
    "\n",
    "A loss function is like a grade you get on a test. It tells you how well you did, and it can help you figure out where you need to improve.\n",
    "\n",
    "For example, let's say you're learning to identify different types of animals. You might be given a picture of a dog, and you have to guess whether it's a golden retriever or a Labrador retriever. If you guess correctly, you get a good grade. But if you guess wrong, you get a bad grade.\n",
    "\n",
    "The loss function works the same way. It tells you how far off your prediction was from the actual output. If your prediction is close to the output, you get a good grade. But if your prediction is far off, you get a bad grade.\n",
    "\n",
    "The loss function is important because it helps you track your progress and see where you need to improve. If you're getting a lot of bad grades, it means you need to study more or practice more. And if you're getting a lot of good grades, it means you're doing a great job and you can keep up the good work.\n",
    "\n",
    "Here is a more mathematical definition of a loss function:\n",
    "\n",
    "```\n",
    "L(y, \\hat{y}) = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "```\n",
    "\n",
    "where $y$ is the actual output, $\\hat{y}$ is the predicted output, and $n$ is the number of data points.\n",
    "\n",
    "The loss function is a measure of how far off the predicted output is from the actual output. The smaller the loss function, the better the prediction.\n",
    "\n",
    "Loss functions are used in machine learning to train models. By minimizing the loss function, we can train models to make better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, I can help you write a class in Python. Here is an example of a class that represents a person:\\n\\n```python\\nclass Person:\\n    def __init__(self, name, age):\\n        self.name = name\\n        self.age = age\\n\\n    def get_name(self):\\n        return self.name\\n\\n    def get_age(self):\\n        return self.age\\n\\n    def set_name(self, new_name):\\n        self.name = new_name\\n\\n    def set_age(self, new_age):\\n        self.age = new_age\\n\\n    def __str__(self):\\n        return \"Person(name=\\'{}\\', age={})\".format(self.name, self.age)\\n```\\n\\nThis class can be used to create objects that represent people. For example, the following code creates a person object named \"John Doe\" who is 30 years old:\\n\\n```python\\nperson = Person(\"John Doe\", 30)\\n```\\n\\nThe `get_name()` and `get_age()` methods can be used to retrieve the person\\'s name and age, respectively. The `set_name()` and `set_age()` methods can be used to change the person\\'s name and age. The `__str__()` method returns a string representation of the person object.\\n\\nI hope this helps!'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new conversation\n",
    "response = palm.chat(messages='i need you to erite me a class in python',\n",
    "                     context='your name is (Name:Close Book) you will tell me if i should countiue chat with you or got to ask \"Text Model\" if the task need a code or many text'\n",
    "                     \n",
    ")\n",
    "# Last contains the model's response:\n",
    "response.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Embeddings/DLCV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import TextGenerator\n",
    "\n",
    "text_generator = TextGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is loss function ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "69 Error functions\n",
      "2.5.1 What is the error function? \n",
      "The error function  is a measure of how “wrong” the neural network prediction is with\n",
      "respect to the expected output (the label). It quantifies how far we are from the cor-\n",
      "rect solution. For example, if we have a high loss, then our model is not doing a good\n",
      "job. The smaller the loss, the better the job the model is doing. The larger the loss,\n",
      "the more our model needs to be trained to increase its accuracy.\n",
      "2.5.2 Why do we need an error function?\n",
      "Calculating error is an optimization problem, something all machine learning engi-\n",
      "neers love (mathematicians, too). Optimization problems focus on defining an error\n",
      "function and trying to optimize its parameters to get the minimum error (more on\n",
      "optimization in the next section). But for now, know that, in general, when we are\n",
      "working on an optimization problem, if we are able to define the error function for\n",
      "the problem, we have a very good shot at solving it by running optimization algo-\n",
      "rithms to minimize the error function.\n",
      " In optimization problems, our ultimate goal is to find the optimum variables\n",
      "(weights) that would minimize the error function as much as we can. If we don’t know\n",
      "how far from the target we are, how will we know what to change in the next iteration?\n",
      "The process of minimizing this error is called error function optimization . We will review\n",
      "several optimization methods in the next section. But for now, all we need to know\n",
      "from the error function is how far we are from the correct prediction, or how much\n",
      "we missed the desired degree of performance. \n",
      "2.5.3 Error is always positive\n",
      "Consider this scenario: suppose we have two data points that we are trying to get our\n",
      "network to predict correctly. If the first gives an error of 10 and the second gives an\n",
      "error of –10, then our average error is zero! This is misleading because “error = 0”\n",
      "means our network is producing perfect predictions, when, in fact, it missed by 10\n",
      "twice. We don’t want that. We want the error of each prediction to be positive, so the\n",
      "errors don’t cancel each other when we take the average error. Think of an archer\n",
      "aiming at a target and missing by 1 inch. We are not really concerned about which\n",
      "direction they missed; all we need to know is how far each shot is from the target.\n",
      " A visualization of loss functions of two separate models plotted over time is shown\n",
      "in figure 2.24. You can see that model #1 is doing a better job of minimizing error,\n",
      "whereas model #2 starts off better until epoch 6 and then plateaus.\n",
      " Different loss functions will give different errors for the same prediction, and thus\n",
      "have a considerable effect on the performance of the model. A thorough discussion\n",
      "of loss functions is outside the scope of this book. Instead, we will focus on the two\n",
      "most commonly used loss functions: mean squared error (and its variations), usually\n",
      "used for regression problems, and cross-entropy, used for classification problems. \n",
      "Loss function is a measure of how \"wrong\" the neural network prediction is with respect to the expected output (the label).\n"
     ]
    }
   ],
   "source": [
    "print(text_generator.generate_answer('What is loss function ?', df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'69 Error functions\\n2.5.1 What is the error function? \\nThe error function  is a measure of how “wrong” the neural network prediction is with\\nrespect to the expected output (the label). It quantifies how far we are from the cor-\\nrect solution. For example, if we have a high loss, then our model is not doing a good\\njob. The smaller the loss, the better the job the model is doing. The larger the loss,\\nthe more our model needs to be trained to increase its accuracy.\\n2.5.2 Why do we need an error function?\\nCalculating error is an optimization problem, something all machine learning engi-\\nneers love (mathematicians, too). Optimization problems focus on defining an error\\nfunction and trying to optimize its parameters to get the minimum error (more on\\noptimization in the next section). But for now, know that, in general, when we are\\nworking on an optimization problem, if we are able to define the error function for\\nthe problem, we have a very good shot at solving it by running optimization algo-\\nrithms to minimize the error function.\\n In optimization problems, our ultimate goal is to find the optimum variables\\n(weights) that would minimize the error function as much as we can. If we don’t know\\nhow far from the target we are, how will we know what to change in the next iteration?\\nThe process of minimizing this error is called error function optimization . We will review\\nseveral optimization methods in the next section. But for now, all we need to know\\nfrom the error function is how far we are from the correct prediction, or how much\\nwe missed the desired degree of performance. \\n2.5.3 Error is always positive\\nConsider this scenario: suppose we have two data points that we are trying to get our\\nnetwork to predict correctly. If the first gives an error of 10 and the second gives an\\nerror of –10, then our average error is zero! This is misleading because “error = 0”\\nmeans our network is producing perfect predictions, when, in fact, it missed by 10\\ntwice. We don’t want that. We want the error of each prediction to be positive, so the\\nerrors don’t cancel each other when we take the average error. Think of an archer\\naiming at a target and missing by 1 inch. We are not really concerned about which\\ndirection they missed; all we need to know is how far each shot is from the target.\\n A visualization of loss functions of two separate models plotted over time is shown\\nin figure 2.24. You can see that model #1 is doing a better job of minimizing error,\\nwhereas model #2 starts off better until epoch 6 and then plateaus.\\n Different loss functions will give different errors for the same prediction, and thus\\nhave a considerable effect on the performance of the model. A thorough discussion\\nof loss functions is outside the scope of this book. Instead, we will focus on the two\\nmost commonly used loss functions: mean squared error (and its variations), usually\\nused for regression problems, and cross-entropy, used for classification problems. '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[86]['Text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "# Close-Book: An AI tool to help CS students in their studies\n",
      "\n",
      "Close-Book is an AI tool that helps CS students in their studies. It provides a variety of features to help students learn and understand CS concepts, including:\n",
      "\n",
      "* **Interactive tutorials:** Close-Book provides interactive tutorials that allow students to learn CS concepts by doing.\n",
      "* **Code generation:** Close-Book can generate code for CS students, helping them to learn how to write code and debug their programs.\n",
      "* **Question answering:** Close-Book can answer questions about CS concepts, helping students to test their understanding of the material.\n",
      "* **Live help:** Close-Book can provide live help to students, answering their questions and helping them to solve problems.\n",
      "\n",
      "Close-Book is a powerful tool that can help CS students to learn and understand CS concepts more effectively. It is available as a web app and as a mobile app.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(text_generator.zero_shot(\"\"\"\n",
    "who are you ? \n",
    "note: answer in markdown format to make the answer simple and looks good\n",
    "\"\"\"))\n",
    "                               "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close-Book: An AI tool to help CS students in their studies\n",
    "\n",
    "## What is Close-Book?\n",
    "\n",
    "Close-Book is an AI-powered tutoring tool that helps CS students learn and understand complex concepts. It provides students with personalized feedback and suggestions, and helps them track their progress.\n",
    "\n",
    "## How does Close-Book work?\n",
    "\n",
    "Close-Book uses a variety of AI techniques to help students learn, including:\n",
    "\n",
    "* **Natural language processing:** Close-Book can understand the questions that students ask, and provide relevant and helpful answers.\n",
    "* **Machine learning:** Close-Book can track students' progress over time, and identify areas where they need additional help.\n",
    "* **Recommendation systems:** Close-Book can recommend resources and activities that are tailored to each student's individual needs.\n",
    "\n",
    "## What are the benefits of using Close-Book?\n",
    "\n",
    "Close-Book can help CS students in a number of ways, including:\n",
    "\n",
    "* **Improved learning outcomes:** Close-Book can help students learn and understand complex concepts more quickly and effectively.\n",
    "* **Increased engagement:** Close-Book can make learning more engaging and interesting for students.\n",
    "* **Reduced stress:** Close-Book can help students feel more confident and less stressed about their studies.\n",
    "\n",
    "## How can I use Close-Book?\n",
    "\n",
    "Close-Book is available as a web app and a mobile app. To use Close-Book, simply sign up for an account and start asking questions. Close-Book will provide you with personalized feedback and suggestions, and help you track your progress.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Close-Book is an AI-powered tutoring tool that can help CS students learn and understand complex concepts. It provides students with personalized feedback and suggestions, and helps them track their progress. If you're a CS student, I encourage you to try Close-Book today!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close-Book: An AI tool to help CS students in their studies\n",
    "\n",
    "I am an AI tool that can help CS students in their studies. I can provide a variety of resources, including:\n",
    "\n",
    "* **Lecture notes:** I can generate lecture notes based on the content of a lecture.\n",
    "* **Code examples:** I can provide code examples that illustrate how to implement different algorithms and data structures.\n",
    "* **Quiz questions:** I can generate quiz questions that test students' understanding of the material.\n",
    "* **Grading:** I can grade students' assignments and provide feedback.\n",
    "\n",
    "I can also help students with their research by:\n",
    "\n",
    "* **Identifying relevant research papers:** I can help students identify research papers that are relevant to their research topic.\n",
    "* **Summarizing research papers:** I can summarize research papers so that students can quickly get the main points.\n",
    "* **Generating research proposals:** I can help students generate research proposals that are well-written and persuasive.\n",
    "\n",
    "I am still under development, but I am learning new things every day. I am excited to help CS students succeed in their studies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Close-Book**, an AI tool to help CS students in their studies.\n",
      "\n",
      "**What is a loss function?**\n",
      "\n",
      "A loss function is a function that measures the difference between the predicted output of a model and the desired output. It is used to evaluate the performance of a model and to guide its training.\n",
      "\n",
      "Loss functions are typically used in supervised learning, where the model is trained on a dataset of labeled data. The loss function is used to calculate the error between the model's predictions and the labels, and this error is used to update the model's parameters.\n",
      "\n",
      "There are many different types of loss functions, each of which is suited to a different type of problem. Some common loss functions include:\n",
      "\n",
      "* Mean squared error (MSE): This is a simple loss function that measures the squared difference between the predicted output and the desired output.\n",
      "* Cross-entropy loss: This is a loss function that is often used for classification problems. It measures the difference between the predicted probability distribution and the true probability distribution.\n",
      "* Kullback-Leibler divergence (KLD): This is a loss function that is often used for measuring the similarity between two probability distributions.\n",
      "\n",
      "The choice of loss function is an important one, as it can have a significant impact on the performance of the model. It is important to choose a loss function that is appropriate for the problem being solved.\n",
      "\n",
      "Here is an example of a loss function for a simple linear regression model:\n",
      "\n",
      "```\n",
      "def loss_function(y_pred, y_true):\n",
      "  \"\"\"Calculates the mean squared error loss.\"\"\"\n",
      "  return np.mean((y_pred - y_true)**2)\n",
      "```\n",
      "\n",
      "This loss function calculates the squared difference between the predicted output and the desired output, and then averages the results across all of the data points in the dataset. This gives a single value that represents the overall error of the model.\n",
      "\n",
      "Loss functions are an essential part of machine learning, and they play a key role in training models to perform well on a given task. By choosing the right loss function, you can improve the performance of your models and get better results.\n"
     ]
    }
   ],
   "source": [
    "print(text_generator.zero_shot(\"\"\"\n",
    "what is loss function?\n",
    "note: answer in markdown format to make the answer simple and looks good\n",
    "\"\"\"))\n",
    "                               "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Close-Book**, an AI tool to help CS students in their studies.\n",
    "\n",
    "**What is a loss function?**\n",
    "\n",
    "A loss function is a function that measures the difference between the predicted output of a model and the desired output. It is used to evaluate the performance of a model and to guide its training.\n",
    "\n",
    "Loss functions are typically used in supervised learning, where the model is trained on a dataset of labeled data. The loss function is used to calculate the error between the model's predictions and the labels, and this error is used to update the model's parameters.\n",
    "\n",
    "There are many different types of loss functions, each of which is suited to a different type of problem. Some common loss functions include:\n",
    "\n",
    "* Mean squared error (MSE): This is a simple loss function that measures the squared difference between the predicted output and the desired output.\n",
    "* Cross-entropy loss: This is a loss function that is often used for classification problems. It measures the difference between the predicted probability distribution and the true probability distribution.\n",
    "* Kullback-Leibler divergence (KLD): This is a loss function that is often used for measuring the similarity between two probability distributions.\n",
    "\n",
    "The choice of loss function is an important one, as it can have a significant impact on the performance of the model. It is important to choose a loss function that is appropriate for the problem being solved.\n",
    "\n",
    "Here is an example of a loss function for a simple linear regression model:\n",
    "\n",
    "```\n",
    "def loss_function(y_pred, y_true):\n",
    "  \"\"\"Calculates the mean squared error loss.\"\"\"\n",
    "  return np.mean((y_pred - y_true)**2)\n",
    "```\n",
    "\n",
    "This loss function calculates the squared difference between the predicted output and the desired output, and then averages the results across all of the data points in the dataset. This gives a single value that represents the overall error of the model.\n",
    "\n",
    "Loss functions are an essential part of machine learning, and they play a key role in training models to perform well on a given task. By choosing the right loss function, you can improve the performance of your models and get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model == emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embeddings'] = df['Embeddings'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a query embbeding\n",
    "query_embedding = palm.generate_embeddings(model=emb_model, text=query)['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.012159031, 0.016000608, -0.07278232, 0.030883648, 0.042206768, 0.00586389, 0.0550859, -0.022852989, -0.020130193, 0.012802268, -0.016075468, 0.03568756, 0.022842498, -0.013605033, -0.010501474, -0.011401135, -0.06247971, -0.03929676, 0.039359335, 0.0037990757, -0.0747627, -0.0034343603, -0.022561323, -0.0017256979, 0.011200434, -0.085254736, 0.04832489, -0.028571256, -0.03516599, -0.0059107984, 0.03864997, 0.020890031, -0.025669849, -0.022951817, -0.039302796, -0.00031840187, -0.06994034, 0.034783173, 0.014722771, 0.0048771105, 0.0062925187, -0.017179891, -0.005620216, 0.025892738, -0.028290072, 0.018652376, -0.092221655, 0.02883248, 0.02158293, -0.04598464, 0.038186383, -0.0130881, -0.036388054, 0.025500996, -0.022145448, 0.016600447, -0.02144096, 0.00028106847, -0.086297065, -0.013628242, 0.0124761835, 0.014433538, 0.02589808, -0.023147896, -0.046706744, 0.085142426, 0.03182272, 0.0028626688, 0.03747989, -0.0062778792, 0.013922257, 0.04080264, 0.012881377, 0.0025034803, 0.08089112, 0.0016156741, 0.02690302, 0.055710666, 0.022991333, -0.014821302, -0.036648005, -0.0597545, -0.027952343, -0.02390833, -0.0044397856, 0.008666068, -0.00121759, 0.06907448, -0.00048499406, 0.0456088, -0.04083496, -0.02205934, -0.010226702, 0.032193873, 0.017441489, 0.005715717, -0.014060458, 0.006570045, -0.059980158, -0.037107345, 0.017574089, -0.03805979, 0.03200524, -0.024453452, 0.01465246, -0.024918111, 0.0018838131, 0.048232418, -0.068065, -0.06823777, -0.07212753, 0.03715635, 0.017204404, 0.082439974, 0.038538657, -0.010606416, 0.031443305, 0.01427507, 0.025710281, -0.00086883974, -0.039658826, -0.032521755, -0.03352989, 0.006761214, 0.07112102, 0.0086367875, -0.008676526, -0.0076787346, -0.06010718, -0.023738278, 0.009586722, -0.0024537393, 0.08666221, -0.07348073, 0.045909647, 0.049782723, -0.0022088394, 0.018245354, -0.030580506, 0.073883995, -0.036360152, 0.017189294, 0.0011224994, 0.02054268, 0.0034353412, -0.04434538, 0.042444248, -0.018768664, -0.042006, -0.03608043, -0.0024463786, -0.055296402, 0.016768636, 0.05014517, 0.018849328, 0.014037272, 0.06731116, 0.046547547, -0.0645875, -0.08507702, 0.022981899, -0.022267923, 0.013103235, 0.015203771, 0.018412264, 0.023682658, -0.0044847704, 0.024172101, 0.0029281245, 0.025053822, 0.04310519, -0.12934214, -0.007440884, -0.027747648, 0.036006328, -0.039900094, -0.0010117476, 0.0019396661, -0.032050375, -0.047602292, 0.00841153, -0.06397827, 0.012357764, -0.012651139, -0.044542085, 0.005369567, -0.03076331, -0.0009070908, -0.04065396, 0.035794936, -0.034592398, -0.027136363, -0.016248882, -0.0884992, -0.047043905, -0.013220168, 0.037916787, -0.063528925, -0.005278326, -0.0031222363, 0.000990205, -0.0142475525, 0.0023492284, -0.003191323, -0.0035716526, -0.020122206, -0.033982802, 0.016784929, -0.0006696648, -0.026761968, -0.006298155, -0.013057518, 0.05193941, -0.044136792, 0.019132841, 0.016553791, -0.009725071, 0.005508722, -0.042577542, -0.00964249, 0.004891328, -0.01099831, 0.023287851, 0.07745614, 0.00037818434, 0.009410954, 0.04177913, 0.015955565, -0.004286627, -0.0009071681, -0.026212798, 0.03224708, 0.030578073, -0.0047771335, -0.009572594, 0.00930541, -0.017859463, -0.071892895, -0.0656631, 0.03755577, -0.040516946, 0.055857465, -0.027070696, 0.053318705, -0.035565313, 0.0360544, -0.0274168, 0.02761016, 0.0029444497, 0.035043195, -0.003082395, -0.04687227, -0.011569565, 0.00075923436, 0.037338685, -0.0063077672, -0.015798073, 0.043593224, -0.0042857965, 0.010658622, 0.01208179, -0.010926007, 0.013349818, 0.105286896, -0.018769287, -0.050861698, -0.07117116, -0.00987489, 0.07818991, -0.034333955, 0.02722702, -0.03186348, 0.029472759, 0.06844745, 0.012134757, 0.002144952, -0.08504519, 0.0130068585, 0.057809293, 0.050139263, -0.013022821, 0.0056768553, 0.00932729, 0.0537154, -0.009372547, -0.0024261018, -0.008952901, -0.04474596, -0.026919523, 0.017174838, -0.00813386, -0.0016532711, -0.034205455, 0.067764856, -0.013088026, 0.033248514, 0.011471435, -0.055521965, -0.018490825, 0.01713351, -0.01921075, -0.0052807587, 0.0641825, -0.05917364, -0.021371212, -0.03542247, -0.004812007, -0.026958099, -0.00056979, 0.027420761, 0.014477239, 0.022330597, 0.00048120724, 0.009699654, -0.049899615, 0.026227465, 0.039725665, -0.019307306, -0.00212113, 0.024987262, -0.025504734, -0.006403634, 0.061178442, -0.0019090652, -0.008002197, 0.002614217, -0.00045881726, -0.012940248, 0.037508354, -0.011078726, -0.00026873557, 0.016856026, 0.0027435306, 0.034092512, -0.0094428705, 0.017320313, 0.011546821, 0.06326555, -0.01305644, -0.03288505, -0.014596046, -0.0041733943, -0.040205523, 0.0048009246, -0.031607132, 0.02430486, -0.05373356, -0.012645491, -0.03934608, -0.065902695, 0.0038540629, 0.012883758, 0.003718596, 0.030626528, 0.021180075, 0.039047983, -0.028521648, 0.010813893, 0.03629976, -0.0046378067, -0.049610607, -0.050360087, -0.0220734, 0.014829911, 0.014604065, 0.008642951, -0.10251179, 0.000117794545, 0.0023714928, -0.004564917, -0.037691806, 0.0050965175, 0.025410475, -0.04858298, -0.09831673, -0.0032652519, -0.016064152, 0.038214438, -0.012480512, -0.0114043765, -0.0061345743, 0.026237793, -0.00861771, -0.0012886386, 0.009902458, 0.002123876, -0.008535988, -0.0068771136, 0.014080259, -0.058681447, 0.029060395, 0.03699728, -0.0060471105, -0.0030997025, -0.010823591, 0.051943135, 0.015911847, -0.014176987, -0.019279197, -0.03722789, -0.000105046536, 0.03125128, -0.037535932, -0.084873185, -0.0036974503, 0.029519718, 0.031200534, 0.061357375, -0.036131695, -0.043039534, -0.022170993, -0.008426702, 0.03162186, -0.011641518, 0.042043585, -0.0011078024, 0.035131942, -0.04397803, -0.03310226, 0.014009904, 0.0040079537, -0.034975663, -0.04784807, 0.038941104, -0.031999435, 0.04201508, -0.037219346, 0.020526309, -0.08664117, -0.015365833, -0.03536255, 0.0018753004, 0.02393874, -0.018662838, 0.007224691, -0.022952737, 0.015256641, 0.07580573, 0.024426786, -0.070284225, 0.0012263617, 0.020986797, -0.03480978, -0.009326117, -0.0034244438, -0.02998444, -0.029492313, -0.019068783, -0.042784736, 0.008167575, -0.060328633, 0.034190558, 0.0028684805, 0.1326134, 0.00989077, -0.006974022, 0.035571072, -0.060059976, 0.020246347, -0.0018348228, -0.015098928, 0.0052917767, -0.02792238, 0.007955664, -0.038275253, -0.02845455, 0.036041673, -0.004882359, -0.03386462, 0.0017240675, -0.017349929, -0.012488553, 0.03502273, 0.005649313, 0.036980916, 0.022829873, 0.033438418, 0.074373625, -0.020965833, -0.061926838, -0.048374463, -0.009592959, -0.024358531, -0.019472923, 0.02596913, -0.0015828883, 0.0019333073, -0.01499682, 0.001898744, -0.026109014, 0.0010869169, -0.056852307, 0.051796615, 0.017198395, -0.04392622, -0.036253247, 0.027086824, -0.01660948, 0.03280752, -0.010105091, 0.026459109, -0.0324225, 0.03247898, 0.041983955, -0.058055386, -0.037561804, 0.050105087, -0.010898407, -0.07636184, 0.07750646, -0.020398416, 0.03914805, -0.046274822, -0.0070458045, -0.051142577, -0.050466955, -0.028054528, 0.037260134, 0.02872526, -0.0034067943, 0.012437291, -0.008342312, 0.022614084, -0.004907457, 0.0076298667, 0.048327144, 0.038097616, 0.005999091, -0.07900943, 0.035140626, 0.04135306, -0.015510848, 0.008250819, 0.05403423, -0.048560962, -0.037131287, 0.00487596, 0.0320546, 0.015583341, 0.06461235, -0.038452145, -0.032269098, 0.03373781, 0.08247031, 0.035287786, 0.054517053, 0.015980376, 0.023063116, 0.0041865245, 0.0384025, 0.02913393, 0.041236337, 0.004413422, 0.13572031, -0.017630992, -0.049469054, 0.058411334, -0.059789058, -0.057140395, -0.032817405, -0.021829145, 0.009155644, -0.043189827, -0.054563005, 0.01855219, -0.014706351, 0.041802417, 0.010820106, 0.051229343, 0.04905428, -0.036100954, -0.027909456, -0.029413465, 0.016330877, -0.026552197, 0.039493803, 0.009655164, 0.049874187, -0.015970444, -0.0023075112, -0.010158323, 0.01515103, 0.0071894634, -0.0073192935, -0.012342541, 0.019866128, 0.012788229, -0.020930618, -0.010391521, 0.008571394, 0.022362838, -0.07429568, -0.027397694, 0.01979451, -0.09234173, -0.022794759, 0.006500247, -0.000947164, -0.025160909, -0.027084762, -0.008799478, 0.031607233, 0.04524481, -0.011475809, 0.051440585, -0.022775283, 0.019760534, 0.0039616968, -0.023103977, 0.038409643, 0.04626776, 0.000844237, 0.0002484388, -0.010090051, -0.025936658, 0.04485416, -0.06563606, 0.055757515, 0.0052389693, 0.027140208, 0.0056670276, -0.043646924, 0.0007899666, -0.0972586, 0.026815973, -0.012762198, 0.015072264, 0.055297177, -0.03024715, -0.012627285, 0.014642537, -0.019126518, -0.0102131, -0.055389464, 0.0243444, -0.0061822943, -0.04330694, -0.0455427, 0.053299062, 0.0210639, 0.07410129, 0.046549186, -0.029326908, 0.0062269056, -0.010531777, -0.025874373, -0.044172954, -0.083282426, -0.02488624, 0.034012835, -0.021059388, -0.0479473, -0.021334114, -0.06450432, 0.0120523935, 0.053524822, -0.037217166, 0.04499435, -0.08746253, 0.047752082, 0.034896955, 0.0038447813, 0.07547397, 0.056723982, -0.034536425, 0.039071936, -0.036874987, 0.04157777, 0.028424762, 0.009035892, -0.045247942, -0.0546059, 0.029646834, -0.014117617, -0.00016195232, 0.00066971045, 0.004201675, 0.03666435, 0.05816209, -0.033850137, -0.047524277, 0.02148782, 0.015108338, 0.00039945508, -0.026652416, -0.028325208, 0.018550288, 0.0012686946, -0.038784117, -0.025017437, 0.031239402, 0.02783456, -0.020650059, -0.07755508, -0.016822271, -0.0077621946, 0.010640857, 0.038792476, -0.01879854, 0.022009443, -0.035924736, 0.03556703, 0.014707727, -0.0012310478, -0.0022725838, -0.059612542, -0.03557467, 0.03355536, -0.024669552, -0.020550344, -0.008740956, -0.0032931727, 0.004836382, 0.045481283, -0.025408521, 0.040754028, -0.048806112, 0.046950724, 0.01892233, 0.019351784, -0.014612375, -0.00085959083, 0.006131751, -0.06358503, 0.005952472, -0.03819602, 0.04160851, -0.015502109, -0.011758064, 0.014151851, 0.02192405, -0.024259036, 0.028404102, 0.013637663, -0.009742824, 0.014809917, 0.02106436, 0.020838747, 0.029552545, -0.047264393, 0.016208658, 0.030471776, 0.025457112, -0.015045394, 0.02850004, -0.012977978, 0.03276036, -0.034512915, 0.025991965, -0.038608335, -0.051700287, 0.016557518, 0.0763386, 0.03461656, -0.023488685, 0.059950963, 0.019630482, 0.007999454, -0.08257666, 0.03636826, -0.017592115, 0.033268936, -0.022049164, -0.016282294, -0.00022414187, -0.0248082, -0.004487569, -0.09609345]\n"
     ]
    }
   ],
   "source": [
    "print(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Embeddings'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.0010041381, 0.023556152, -0.02987321, 0.060834404, 0.046326395, -0.02630725, 0.05149295, 0.0015270954, -0.018965637, 0.008094878, 0.012878272, -0.033970058, 0.040260054, -0.007773982, -0.030728519, -0.0038723545, -0.02165675, -0.048108336, 0.029629802, 0.025192019, -0.06654851, -0.005221891, 0.0036930973, 0.026820462, 0.0017714327, -0.064580396, 0.012046766, -0.049813602, -0.03230159, -0.008825886, 0.014978497, 0.029564464, -0.013146918, -0.01330665, 0.04299503, 0.035856884, -0.004783798, 0.013250478, -0.0061364244, 0.047982816, -0.029000968, -0.068525404, 0.04028211, -0.0036428156, -0.016990067, -0.041494105, -0.024780551, -0.028861785, -0.014957387, -0.06511688, 0.0026707454, -0.05473773, 0.034465656, 0.023149969, 0.03929322, 0.034097876, -0.02163697, -0.030744692, -0.068379305, -0.014454069, 0.025074236, -0.000844103, 0.016302546, -0.03107995, -0.008877413, 0.025613071, -0.0059933336, -0.019427288, 0.016761009, -0.033954676, -0.002195716, 0.025517033, -0.041232422, -0.026811454, 0.05143343, -0.004568858, 0.020345753, 0.021341782, -0.009535598, -0.0345916, -0.0044232137, 0.012625406, -0.046848416, -0.08846693, 0.01565361, 0.029342463, -0.030428438, -0.013319169, -0.050929513, 0.030914932, -0.031118702, -0.0024630392, 0.0032481207, 0.028432244, -0.03871257, 0.006139455, 0.015196526, 0.009445552, -0.0034639093, -0.037273172, -0.0035627699, -0.052062508, 0.05829942, -0.033773992, 0.047804013, -0.033353955, -0.018767059, 0.06419501, -0.030194707, -0.106464595, -0.039822344, -0.010775398, -0.0401875, -0.007703008, 0.007926779, -0.00823471, -0.0010128451, 0.0055165556, 0.05669459, -0.011237376, -0.030139416, -0.051632196, -0.04454238, -0.0088331215, 0.0028095169, -0.036525916, 0.055197854, 0.017468056, -0.05154899, 0.040193986, 0.03205528, -0.003319763, 0.026138619, -0.042143423, -0.015451853, 0.033170607, -0.01652432, -0.041649994, 0.042908948, 0.01980751, -0.09899582, -0.048337515, -0.027592814, 0.010187125, 0.006883349, -0.04545956, -0.013108255, -0.02141738, -0.0791462, -0.08620872, -0.034737542, -0.014970368, 0.01818069, 0.11798178, 0.05630898, 0.025477204, 0.02285654, 0.022366969, 0.0025029895, -0.06079575, -0.019635778, -0.02858483, -0.01805591, -0.01711215, 0.04405408, 0.035443697, 0.038590856, -0.010812633, -0.019790422, 0.013351156, 0.08036937, -0.15055688, 0.008960675, -0.014158201, 0.06457216, -0.017651435, -0.02453054, 0.012055023, 0.016912889, -0.0428644, -0.0066139624, -0.060628794, -0.012225723, -0.020642204, -0.06188126, 0.06646375, -0.026173485, -0.040843762, -0.07467873, 0.07909232, -0.02137919, 0.03355228, -0.0061276886, -0.087117754, -0.013367253, -0.028627424, 0.045442555, -0.08437869, 0.009193202, 0.017816305, -0.011361139, -0.051518485, 0.031390164, 0.026296336, -0.03562775, -0.04932379, 0.032249548, 0.013266413, -0.010890159, -0.020223368, -0.020164775, 0.0013865785, 0.027758732, 0.014048204, 0.017359655, 0.009662, 0.011708762, -0.01145324, -0.08277662, -0.0020719771, -0.023032704, 0.016964966, 0.0018921243, 0.08714893, -0.016399004, 0.029045017, 0.03923643, -0.0040885336, 0.027748315, 0.004413473, -0.00033016806, -0.013461643, -0.0042064297, 0.009067933, -0.012865621, 0.057316303, 0.014568659, -0.02700402, -0.0686138, 0.01820987, 0.022474583, 0.0916525, -0.05863418, 0.024541069, -0.025788069, 0.017059097, -0.0157864, 0.014186885, 0.013278917, -0.01622046, 0.037869796, -0.030587437, 0.0411583, -0.030432235, 0.012804792, -0.006258391, -0.0050368286, 0.026263926, 0.0338823, 0.029384358, 0.02461304, 0.04825086, 0.053304665, 0.13443525, -0.045265608, -0.016090792, -0.046225406, 0.02055322, 0.047884516, -0.04540333, -0.0035181122, -0.029338649, -0.0010192867, 0.06095491, -0.00592104, -0.023741145, -0.04021079, 0.03399003, -0.0057776757, 0.06073965, -0.009067686, -0.016104573, 0.038281884, 0.0313304, -0.0038257842, -0.009044271, 0.0031150144, 0.0036959702, -0.064078294, -0.016452426, 0.0242015, 0.047853053, -0.045662083, 0.0104679195, 0.0028583363, 0.020398729, 0.031091297, -0.061199088, 0.022219157, 0.029172946, 0.015124049, -0.0026777962, 0.009834246, -0.029241608, -0.03156369, 0.009278338, -0.016571611, -0.0206066, 0.051894587, 0.0044654915, -0.03462328, -0.03062156, -0.030602405, 0.013050234, -0.032939438, 0.0023256135, 0.056957312, 0.0029298079, -0.05850608, 0.044340283, -0.010605034, 0.019694367, 0.09780489, -0.01676125, 0.066592194, -0.004846235, -0.021585925, -0.01175356, 0.029531097, -0.11071704, -0.0098312255, 0.08194798, 0.0022515203, 0.030496428, -0.026409859, -0.03886326, 0.020600773, -0.023000041, 0.0152085135, -0.038997147, 0.015676832, -0.08347846, -0.04684115, -0.011759208, -0.0001882242, 0.03545987, -0.054570053, -0.027716715, -0.04342667, -0.07580669, -0.011785074, 0.06872395, -0.008235138, 0.014568397, 0.0044588256, 0.027487935, 0.06525055, 0.013233426, 0.03255504, 0.006855561, -0.02949596, 0.028256586, -0.049418855, 0.043520294, -0.008868325, 0.0012297062, -0.07008372, -0.026538981, 0.01350661, -0.0068788496, 0.019898696, 0.018342877, 0.0362356, -0.0018642892, -0.059587814, 0.0161104, 0.008191178, 0.0061004176, 0.0341109, -0.00083038566, 0.026148848, 0.059906553, -0.018406011, -0.009741092, 0.01095568, 0.026761381, 0.0014959164, 0.039362263, 0.006174232, 0.0057295556, 0.018274443, 0.029448759, 0.0029526828, -0.03375693, -0.006680042, 0.031015854, -0.022867287, 0.018440153, -0.0052930517, -0.0036561533, -1.0280971e-05, -0.016407968, -0.035440452, -0.059465516, 0.013305081, -0.014256664, 0.076467164, 0.087662436, 0.009348245, -0.012565749, 0.008061092, -0.020433083, -0.02420474, 0.010913809, 0.043521337, -0.015397629, -0.022011131, -0.027201658, 0.011314515, 0.036496893, -0.0020963924, -0.026895696, -0.062506475, 0.021315834, 0.033086076, 0.0032006875, -0.052844282, 0.03291413, 0.03338169, -0.016483903, -0.010937526, -0.033210337, 0.023523044, -0.061614428, 0.0054139164, -0.03175822, 0.09560746, 0.08078127, -0.021486262, -0.015728718, -0.043357287, 0.024308361, 0.007818711, 0.024498755, 0.0022792388, -0.0035508426, -0.032390084, -0.048496258, -0.046928607, 0.011149136, -0.011456083, 0.0066230786, 0.053148665, 0.076152615, -0.014120323, 0.042238407, 0.007565136, -0.023931883, 0.024208361, -0.006413898, -0.053534776, 0.035126317, 0.011684442, 0.06405931, -0.044824462, 0.03820536, 0.0061377846, -0.0047030416, 0.029091684, 0.049508702, -0.057844754, 0.0014466341, 0.012133875, -0.032478064, 0.037905905, 0.022057297, 0.042063747, 0.060533542, -0.05013231, -0.037685223, -0.06759806, 0.01254163, -0.030158218, -0.052911974, 0.027708502, 0.06816565, 0.0060618254, 0.011577901, -0.010083743, 0.03316828, 0.043981537, -0.032621413, 0.032003097, -0.024129737, -0.021216508, 0.018173521, 0.038525317, -0.007417053, 0.04612401, 0.03755702, 0.025923949, -0.009377379, -0.013445976, -0.011388348, 0.010446866, -0.0016684736, 0.016965559, -0.086331345, -0.049861252, -0.008463646, 0.06530282, -0.00015800259, 0.021112703, -0.050990976, -0.032574102, -0.046207856, -0.007936902, 0.0056990306, -0.010698335, 0.0022987372, 0.022514578, -0.0076915403, 0.0005334078, -0.012907087, 0.04865672, 0.04712516, -0.010611942, 0.00024986046, -0.019326402, -0.0098807085, 0.0049858, 0.0794187, 0.015888456, 0.005509397, 0.038852226, -0.0286864, 0.014217757, 0.02011075, 0.040575232, 0.082102105, -0.06704182, -0.07773001, -0.00085922406, 0.023943665, -0.026048752, -0.009868908, -0.005054697, 0.0368044, 0.040667042, -0.015810788, 0.014964093, -0.05270619, -0.05551698, 0.08179615, -0.03334504, -0.01910446, 0.018370334, -0.025230106, -0.03651315, 0.003247846, 0.058031633, -0.033319764, -0.019274633, 0.04444165, 0.021931902, -0.0016367044, 0.06003394, 0.080456495, -0.007863981, 0.04865963, 0.03185988, -0.022421872, -0.01020077, 0.030682838, -0.0060435496, 0.0058102184, -0.009635739, 0.029827593, -0.01468937, -0.0038723305, -0.023970228, -0.0018497652, -0.0024182408, 0.0057781423, -0.07310701, -0.06429613, -0.014240717, -0.024381114, 0.03461318, -0.0051983553, 0.023904642, -0.04634926, 0.06734993, 0.020684177, -0.016118465, -0.023086302, -0.011580142, -0.038567223, 0.014740945, 0.008636611, -0.0055265725, -0.00020714349, 0.058747005, -0.037502825, 0.0011044947, -0.0041146367, 0.062111534, 0.039666113, -0.018521866, 0.022927143, 0.016441394, 0.07302953, 0.02882419, 0.037818655, -0.031982277, -0.023607593, -0.045134533, 0.01361864, -0.0053525106, 0.05794421, 0.03165355, 0.058043536, -0.012703732, -0.014480424, 0.013357041, 0.006655442, 0.046172813, 0.026117502, -0.014993065, -0.01907732, 0.08604951, -0.004547226, -0.020758519, -0.058609076, -0.022170842, -0.02450167, -0.0216691, 0.025496304, 0.050829727, 0.006285216, 0.03078578, 0.030744191, 0.016023356, 0.023517113, -0.026655806, 0.024541268, -0.04027151, -0.05720538, -0.009739316, 0.014212831, -0.0069325487, -0.017361479, -0.0011531087, -0.073749356, -0.041812528, 0.010388862, -3.88536e-05, 0.01577667, -0.00392907, 0.020104403, 0.026326455, -0.050177634, 0.03569844, 0.011206269, -0.043079015, 0.04080811, -0.012840485, 0.04957604, 0.005813117, 0.0031428079, -0.00755317, -0.032562207, 0.045656316, -0.06494383, 0.0033428564, -0.009764235, 0.03255727, 0.06191275, 0.04436002, 0.026593227, -0.009797906, -0.028733272, -0.0030899332, -0.07286433, 0.012299978, -0.05008531, 0.026587397, 0.012797291, 0.010987442, 0.04116657, 0.029847743, 0.014994581, -0.0072425394, -0.010375042, -0.028528476, -0.058258906, -0.03534101, 0.0062763426, 0.021964887, -0.0007688426, -0.044253573, 0.0015769742, 0.04020213, 0.002135937, 0.021843057, 0.00028613562, -0.033182442, 0.06351926, -0.00085236126, -0.037533525, -0.005790126, -0.001225871, 0.017449388, 0.038122952, -0.004859644, 0.029097501, -0.03368055, -0.006559767, 0.053953823, 0.009928121, 0.038290042, 0.02832133, 0.013332583, -0.045405593, -0.061270278, 0.0005129303, 0.037714567, -0.04160036, 0.016118849, 0.0042507797, -0.025485368, -0.009542548, 0.024509594, 0.050056152, 0.036466938, 0.009221391, 0.015076832, -0.01233212, 0.035954285, -0.011535738, -0.010790927, -0.0028713692, -0.027001727, 0.0015588157, 0.004908564, -0.02631012, 0.012869125, -0.020543847, -0.038131814, -0.02009232, -0.057851072, 0.02287365, -0.012260979, 0.04120868, -0.03920476, 0.09233699, 0.023064267, 0.045607194, -0.0600811, 0.03421658, -0.015915606, 0.039867304, -0.005605976, 0.023175867, 0.058742672, -0.017166357, -0.041096527, 0.0044870153]'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['Embeddings'][0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "x = ast.literal_eval(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader  #load urls into docoument-loader\n",
    "urls = ['https://www.linkedin.com/pulse/transformers-without-pain-ibrahim-sobh-phd/','https://www.linkedin.com/pulse/transformers-without-pain-ibrahim-sobh-phd/']\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m loader \u001b[39m=\u001b[39m UnstructuredURLLoader(urls\u001b[39m=\u001b[39murls)\n\u001b[0;32m----> 3\u001b[0m text \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m      4\u001b[0m text \u001b[39m=\u001b[39m text[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mpage_content\n\u001b[1;32m      5\u001b[0m text_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mText\u001b[39m\u001b[39m'\u001b[39m: [text]}\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/langchain/document_loaders/url.py:106\u001b[0m, in \u001b[0;36mUnstructuredURLLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_non_html_available():\n\u001b[1;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_headers_available_for_non_html():\n\u001b[0;32m--> 106\u001b[0m         elements \u001b[39m=\u001b[39m partition(\n\u001b[1;32m    107\u001b[0m             url\u001b[39m=\u001b[39;49murl, headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munstructured_kwargs\n\u001b[1;32m    108\u001b[0m         )\n\u001b[1;32m    109\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m         elements \u001b[39m=\u001b[39m partition(url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munstructured_kwargs)\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/unstructured/partition/auto.py:102\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(filename, content_type, file, file_filename, url, include_page_breaks, strategy, encoding, paragraph_grouper, headers, ssl_verify, ocr_languages, pdf_infer_table_structure, xml_keep_tags, data_source_metadata, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m exactly_one(file\u001b[39m=\u001b[39mfile, filename\u001b[39m=\u001b[39mfilename, url\u001b[39m=\u001b[39murl)\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m url \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     file, filetype \u001b[39m=\u001b[39m file_and_type_from_url(\n\u001b[1;32m    103\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    104\u001b[0m         content_type\u001b[39m=\u001b[39;49mcontent_type,\n\u001b[1;32m    105\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    106\u001b[0m         ssl_verify\u001b[39m=\u001b[39;49mssl_verify,\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m headers \u001b[39m!=\u001b[39m {}:\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/unstructured/partition/auto.py:263\u001b[0m, in \u001b[0;36mfile_and_type_from_url\u001b[0;34m(url, content_type, headers, ssl_verify)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfile_and_type_from_url\u001b[39m(\n\u001b[1;32m    258\u001b[0m     url: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    259\u001b[0m     content_type: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    260\u001b[0m     headers: Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m {},\n\u001b[1;32m    261\u001b[0m     ssl_verify: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    262\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[io\u001b[39m.\u001b[39mBytesIO, Optional[FileType]]:\n\u001b[0;32m--> 263\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49mheaders, verify\u001b[39m=\u001b[39;49mssl_verify)\n\u001b[1;32m    264\u001b[0m     file \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(response\u001b[39m.\u001b[39mcontent)\n\u001b[1;32m    266\u001b[0m     content_type \u001b[39m=\u001b[39m content_type \u001b[39mor\u001b[39;00m response\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    749\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mread(amt)\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "text = loader.load()\n",
    "text = text[0].page_content\n",
    "text_dict = {'Text': [text]}\n",
    "df = pd.DataFrame(text_dict)\n",
    "# df.columns = ['Text']        \n",
    "# df['Embeddings'] = df['Text'].apply(self.make_embeddings)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformers without pain \\uf8ffü§ó\\n\\nReport this article\\n\\nIbrahim Sobh - PhD\\n\\nIbrahim Sobh - PhD\\n\\n\\uf8ffüéì Senior Expert of Artificial Intelligence, Valeo Group | Machine Learning | Deep Learning | Data Science | Computer Vision | NLP | Lecturer | Developer | Researcher \\uf8ffüìù\\n\\nPublished Jan 4, 2021\\n\\n+ Follow\\n\\nContents:\\n\\nWhat is wrong with RNNs and CNNs\\n\\nA High-Level Look\\n\\nMachine Translation Task\\n\\nArchitecture main components\\n\\nWhat is attention? Where is attention?\\n\\nHow to represent the order of words without RNNs?\\n\\nGenerating words\\n\\nThe big picture\\n\\nThe future is here\\n\\nHow to start?\\n\\n1) What is wrong with RNNs and CNNs\\n\\nLearning Representations of Variable Length Data is a basic building block of sequence-to-sequence learning for Neural machine translation, summarization, etc\\n\\nRecurrent Neural Networks are natural fit variable-length sentences and sequences of pixels. But sequential computation inhibits parallelization. No explicit modeling of long and short-range dependencies.\\n\\nConvolutional Neural Networks are trivial to parallelize (per layer) and exploit local dependencies. However, long-distance dependencies require many layers.\\n\\nAttention between encoder and decoder is crucial in NMT.\\n\\nThe Transformer was proposed in the paper Attention is All You Need.\\n\\nRIP RNNs and CNNs!\\n\\n2) A High-Level Look\\n\\nI know, this looks scary! However, the idea is very simple. Let\\'s abstract and simplify everything for a better understanding, without pain (hopefully).\\n\\n3) Machine Translation Task\\n\\nMachine Translation (MT) is the task of translating a sentence x from one language (the source language) to a sentence y in another language (the target language).\\n\\nInput: a sequence of source tokens (words/word pieces)\\n\\nOutput: a sequence of target tokens (words/word pieces)\\n\\n4) Architecture main components\\n\\nEncoder component and Decoder component (No RNN!)\\n\\nThe encoding component is a stack of 6 encoders, each encoder is composed of a number of layers.\\n\\nThe decoding component is a stack of 6 decoders, each decoder is composed of a number of layers.\\n\\nSo far, this should look familiar, just encoder and decoder, where the decoder has access to some output of the encoder. But, where is the magic? No RNNs, while learning the sequences for machine translation is based on attention mechanism!\\n\\n5) What is attention? Where is attention?\\n\\nCore idea: on each step of the decoder, use a direct connection to the encoder to focus on a particular part of the source sequence.\\n\\nAn example fo using attention for machine translation is discussed here \"Attention\" for Neural Machine Translation (NMT) without pain\\n\\nSelf Attention in the Encoder: the word \"self\" is used here to indicate that each input word to the encoder (a vector of real numbers) is projected (or transformed) via learnable parameters of NN to another vector that is actually some sort of weighted sum of the other words in the input. Accordingly, each word in the input will attend to different words in the same input, this is a self-attention. Remember, we have 6 encoders where each input word is transformed along its way till the last encoder.\\n\\nSelf-attention basic steps:\\n\\nAssume the input word is represented as a vector (embedding) with a dimensionality of 512.\\n\\nEach word is projected into three other vectors, each of which with a dimensionality of 64. (imagine we have fully connected layers with 512 input and 64 outputs)\\n\\nThese vectors are called query (q), key (k), and value (v). (These terms are related to information retrieval). This is a generalization of the same idea of seq2seq machine translation with attention.\\n\\nAs shown in the figure, the query vector is used to compute a weighted sum of the values through the keys. Specifically: q dot product all the keys, then softmax to get weights and finally use these weights to compute a weighted sum of the values.\\n\\nMultihead attention: the intuition is similar to have a multi-filter in CNNs. Here we can have multi-head attention, to give the network more capacity and ability to learn different attention patterns.\\n\\nFor example, a word w may attend to word x in head 1 (representing some semantic connection) the same word w attends to another word b in another head. Actually we have 8 attention heads and accordingly, the 8 projections (q, k, and v) are concatenated to have vectors of 8*64 = 512 dimensionalities (same as the input word embeddings).\\n\\nSelf Attention in the Decoder: This is the same as in the encoder, except that the decoder has access to the whole input sequence (past, present, and future words), while the encoder has access only to the past and present words and can not see the future words, they are not generated yet. This is why it is called masked self-attention because the future words are masked out.\\n\\nEncoder-decoder attention: This is not a self-attention, it is the attention used by the decoder to attend or focus on values from the encoder. The decoder uses the query vector to be applied to the key and value vectors provided by the encoder.\\n\\nAs shown, we have 3 connected arrows in the first self-attention layers for both encoder and decoder indicating the q, k, and v vectors. While in the encoder-decoder attention layer on the encoder, we have only one arrow from the decoder itself representing the q one vector for the current token, and 2 other arrows from the encoder to pass the k and v vectors (for the whole input sequence).\\n\\n6) How to represent the order of words without RNNs?\\n\\nPositional Encoding is used to represent the order of the sequence. The transformer adds a vector to each input embedding. These vectors follow a specific pattern (generated offline) that the model learns, which helps it determine the position of words and the distance between different words in a sequence. Positional Encodings are added only to the input of both the encoder and the decoder\\xa0components.\\n\\nThink of the positional encoders as a simple lookup table of vectors (based on sin and cos functions) added to the original word embeddings, based on the word position in the sequence.\\n\\nAdditional note: In these architectures, we can see that each sub-layer (self-attention, fully connected) has a residual connection around it (think of ResNet), and is followed by a layer-normalization step. Simply, the output from the Multi-head attention block or the Feed-forward block is merged with the residual (addition), and the result is layer normalized.\\n\\nÔªø7) Generating words\\n\\nThe last layer of the decoder is a softmax layer that predicts probability distribution over the vocabulary words at time t+1, based on the predicted words from 1 to t (input to the decoder), and also based on the encoder provided information about the input sequence. Think of the decoder as an autoregressive conditional language model that generates words one by one.\\n\\n8) The big picture\\n\\nAttention is all you need, literally!\\n\\nTransformers are used for seq2seq machine translation tasks, without RNN, without CNN.\\n\\nAttention is applied within the same sequence (self-attention) and between the encoder and decoder.\\n\\nSequence order is maintained via positional encoders.\\n\\nFor translation tasks, Transformers are trained on bilingual datasets (ex WMT 2014 English-to-German)\\n\\n9) The future is here\\n\\nBased on this architecture (the vanilla Transformers!), encoder or decoder components are used alone to enable massive pre-trained generic models that can be used and fine-tuned for downstream tasks such as text classification, translation, summarization, question answering, etc.\\n\\nFor Example, \"Pre-training of Deep Bidirectional Transformers for Language Understanding\" BERT is mainly based on the encoder architecture trained on massive text datasets to predict randomly masked words and \"is-next sentence\" classification task. GPT, on the other hand, is an auto-regressive generative model (unlike BERT, GPT can generate sequences) that is mainly based on the decoder architecture (with masked self-attention and without the encoder-decoder attention).\\n\\nHere is a nice source code that implements a Transformer block as a Keras layer and uses it for text classification.\\n\\nMoreover, Transformers are recently used for computer vision tasks such as classification and object detection.\\n\\n10) How to start? \\uf8ffü§ó\\n\\n\\uf8ffü§ó Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation, etc in 100+ languages. Its aim is to make cutting-edge NLP easier to use for everyone.\\n\\n\\uf8ffü§ó Transformers is backed by the two most popular deep learning libraries, PyTorch and TensorFlow, with seamless integration between them, allowing you to train your models with one then load it for inference with the other.\\n\\nhuggingface/transformers\\n\\nReferences:\\n\\nCS224n: Natural Language Processing with Deep Learning Stanford / Winter 2019\\n\\nThe Illustrated-Transformer\\n\\nLike\\n\\nLike\\n\\nCelebrate\\n\\nSupport\\n\\nLove\\n\\nInsightful\\n\\nFunny\\n\\nLike\\n\\nCelebrate\\n\\nSupport\\n\\nLove\\n\\nInsightful\\n\\nFunny\\n\\nComment\\n\\nCopy\\n\\nLinkedIn\\n\\nFacebook\\n\\nTwitter\\n\\nShare\\n\\n70\\n\\n3 Comments\\n\\nAmir Salah\\n\\nSoftware Engineer at nandbox\\n\\n2y\\n\\nReport this comment\\n\\nThat was my first time to truly grasp the idea of Transformers. Thanks, Doctor.\\n\\nLike\\n\\nReply\\n\\n1\\xa0Reaction\\n\\nMohamed Tawfik\\n\\nAdobe Magento Solution Specialist, Adobe Magento Developer,  Christian Louboutin, ZamTech Ltd, Valtech\\n\\n2y\\n\\nReport this comment\\n\\nSuch an amazing article \\nThanks\\n\\nLike\\n\\nReply\\n\\n1\\xa0Reaction\\n\\n2\\xa0Reactions\\n\\nSee more comments\\n\\nTo view or add a comment, sign in\\n\\nMore articles by this author\\n\\nNo more previous content\\n\\n[\\uf8ffùë∫\\uf8ffùíï\\uf8ffùíÇ\\uf8ffùíÉ\\uf8ffùíç\\uf8ffùíÜ] \\uf8ffùíÖ\\uf8ffùíä\\uf8ffùíá\\uf8ffùíá\\uf8ffùíñ\\uf8ffùíî\\uf8ffùíä\\uf8ffùíê\\uf8ffùíè \\uf8ffùíé\\uf8ffùíê\\uf8ffùíÖ\\uf8ffùíÜ\\uf8ffùíç\\uf8ffùíî explained with code \\uf8ffü§ó\\n        \\n\\n          \\n            \\n        Jan 28, 2023\\n\\nA conversation with ChatGPT about AI, study roadmap, applications, interview questions with answers, salaries, and more!\\n        \\n\\n          \\n            \\n        Jan 21, 2023\\n\\n10 Object detectors with code [YOLOF, YOLOX, DETR, Deformable DETR, SparseR-CNN, VarifocalNet, PAA, SABL, ATSS, Double Heads]\\n        \\n\\n          \\n            \\n        Feb 17, 2022\\n\\nFNet: Do we need the attention layer at all? [Explained with code]\\n        \\n\\n          \\n            \\n        Oct 30, 2021\\n\\nPatches Are All You Need! [with code]\\n        \\n\\n          \\n            \\n        Oct 28, 2021\\n\\nMLP is all you need! [with code]\\n        \\n\\n          \\n            \\n        Oct 23, 2021\\n\\n9 Steps for solving any machine learning problem\\n        \\n\\n          \\n            \\n        Aug 28, 2021\\n\\nAnatomy of the Beast with many heads! [with code]\\n        \\n\\n          \\n            \\n        Jun 12, 2021\\n\\nThe magic of XLM-R: Unsupervised Cross-lingual Representation Learning at Scale\\n        \\n\\n          \\n            \\n        Jan 16, 2021\\n\\nHow multilingual is Multilingual BERT? \\n        \\n\\n          \\n            \\n        Jan 11, 2021\\n\\nNo more next content\\n\\nSee all\\n\\nOthers also viewed\\n\\n\"Attention\" for Neural Machine Translation (NMT) without pain\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Ibrahim Sobh - PhD\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      2y\\n\\nAUC, Computer Science and Engineering, 2023\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Karim Sobh\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      1w\\n\\n7 Steps to Successful Network Optimization Modeling\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Bruce Dzinski\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      2y\\n\\nMODNet: Remove Background in real-time  [Demo and code included]\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Ibrahim Sobh - PhD\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      2y\\n\\nProbabilistic Language Models\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Ibrahim Sobh - PhD\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      3y\\n\\nDeep Learning for image search engines [code included]\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Ibrahim Sobh - PhD\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      3y\\n\\nAnatomy of sequence-to-sequence for Machine Translation (Simple RNN, GRU, LSTM) [Code Included]\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Ibrahim Sobh - PhD\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      3y\\n\\nNeural Language Models (NLM) without pain\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Ibrahim Sobh - PhD\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      2y\\n\\nDeep Learning: Deep Dreaming\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Ibrahim Sobh - PhD\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      6y\\n\\nDiscriminative vs Generative model\\n      \\n          \\n\\n\\n\\n\\n            \\n              \\n          \\n            Ibrahim Sobh - PhD\\n          \\n          \\n            \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n    \\n\\n      5y\\n\\nExplore topics\\n\\nSales\\n\\nMarketing\\n\\nBusiness Administration\\n\\nHR Management\\n\\nContent Management\\n\\nEngineering\\n\\nSoft Skills\\n\\nSee All'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embeddings(text):\n",
    "    return palm.generate_embeddings(model=emb_model,text=text)['embedding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [m for m in palm.list_models() if 'embedText' in m.supported_generation_methods]\n",
    "emb_model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 Request payload size exceeds the limit: 10000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/grpc/_channel.py:1030\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1028\u001b[0m state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m   1029\u001b[0m                               wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/grpc/_channel.py:910\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Request payload size exceeds the limit: 10000 bytes.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.37.202:443 {grpc_message:\"Request payload size exceeds the limit: 10000 bytes.\", grpc_status:3, created_time:\"2023-07-02T06:46:34.273179633+03:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mEmbeddings\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mText\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(make_embeddings)\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mmake_embeddings\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_embeddings\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mreturn\u001b[39;00m palm\u001b[39m.\u001b[39;49mgenerate_embeddings(model\u001b[39m=\u001b[39;49memb_model,text\u001b[39m=\u001b[39;49mtext)[\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/google/generativeai/text.py:196\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[0;34m(model, text, client)\u001b[0m\n\u001b[1;32m    193\u001b[0m     client \u001b[39m=\u001b[39m get_default_text_client()\n\u001b[1;32m    195\u001b[0m embedding_request \u001b[39m=\u001b[39m glm\u001b[39m.\u001b[39mEmbedTextRequest(model\u001b[39m=\u001b[39mmodel, text\u001b[39m=\u001b[39mtext)\n\u001b[0;32m--> 196\u001b[0m embedding_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49membed_text(embedding_request)\n\u001b[1;32m    198\u001b[0m embedding_dict \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(embedding_response)\u001b[39m.\u001b[39mto_dict(embedding_response)\n\u001b[1;32m    200\u001b[0m embedding_dict[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m embedding_dict[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta2/services/text_service/client.py:754\u001b[0m, in \u001b[0;36mTextServiceClient.embed_text\u001b[0;34m(self, request, model, text, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    749\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(metadata) \u001b[39m+\u001b[39m (\n\u001b[1;32m    750\u001b[0m     gapic_v1\u001b[39m.\u001b[39mrouting_header\u001b[39m.\u001b[39mto_grpc_metadata(((\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mmodel),)),\n\u001b[1;32m    751\u001b[0m )\n\u001b[1;32m    753\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m    755\u001b[0m     request,\n\u001b[1;32m    756\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m    757\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    758\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    761\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/run/media/ahmed/Hay/Colse Book ver/Close Book last/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:74\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Request payload size exceeds the limit: 10000 bytes."
     ]
    }
   ],
   "source": [
    "# df['Embeddings'] = df['Text'].apply(make_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [m for m in palm.list_models() if 'embedText' in m.supported_generation_methods]\n",
    "emb_model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers without pain ü§ó\\n\\nReport this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Convolutional Neural Networks are trivial to p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4) Architecture main components\\n\\nEncoder com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An example fo using attention for machine tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Each word is projected into three other vector...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Transformers without pain ü§ó\\n\\nReport this ...\n",
       "1  Convolutional Neural Networks are trivial to p...\n",
       "2  4) Architecture main components\\n\\nEncoder com...\n",
       "3  An example fo using attention for machine tran...\n",
       "4  Each word is projected into three other vector..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter #text splitter\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "texts = loader.load()\n",
    "text_list = []\n",
    "for text in texts:\n",
    "    text_list.append(text.page_content)\n",
    "splitter = CharacterTextSplitter(chunk_size=1000)\n",
    "pargraphs = splitter.create_documents(text_list)\n",
    "pargraphs_text=[]\n",
    "for pra in pargraphs:\n",
    "    pargraphs_text.append(pra.page_content)\n",
    "text = {'Text':pargraphs_text}\n",
    "df = pd.DataFrame(text)\n",
    "# df['Embeddings'] = df['Text'].apply(make_embeddings)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embeddings'] = df['Text'].apply(make_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_text_list = ['https://www.linkedin.com/pulse/transformers-without-pain-ibrahim-sobh-phd/','https://www.linkedin.com/pulse/transformers-without-pain-ibrahim-sobh-phd/']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import TextGenerator\n",
    "text_generator = TextGenerator()\n",
    "df = text_generator.make_urls_df(urls_text_list)\n",
    "# ans = text_generator.get_genrate_url_answer(query, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers without pain ü§ó\\n\\nReport this ...</td>\n",
       "      <td>[0.0010315055, -0.028580409, -0.0076014455, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Convolutional Neural Networks are trivial to p...</td>\n",
       "      <td>[-0.0009383782, -0.0289818, -0.023477007, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4) Architecture main components\\n\\nEncoder com...</td>\n",
       "      <td>[-0.020651396, -0.01635578, -0.024015633, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An example fo using attention for machine tran...</td>\n",
       "      <td>[-0.0097579835, -0.008790414, -0.018799463, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Each word is projected into three other vector...</td>\n",
       "      <td>[-0.01479975, -0.025010662, -0.04422533, 0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For example, a word w may attend to word x in ...</td>\n",
       "      <td>[-0.009083958, -0.02020066, -0.030411098, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>As shown, we have 3 connected arrows in the fi...</td>\n",
       "      <td>[-0.00903019, -0.008585256, -0.031742916, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Think of the positional encoders as a simple l...</td>\n",
       "      <td>[-0.015467625, -0.03785381, -0.04217757, 0.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8) The big picture\\n\\nAttention is all you nee...</td>\n",
       "      <td>[-0.018798167, -0.013468233, -0.01657415, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For Example, \"Pre-training of Deep Bidirection...</td>\n",
       "      <td>[-0.002645978, -0.012628271, 0.0039097792, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Moreover, Transformers are recently used for c...</td>\n",
       "      <td>[0.0011646682, -0.01502404, 0.006865669, 0.048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Like\\n\\nLike\\n\\nCelebrate\\n\\nSupport\\n\\nLove\\n...</td>\n",
       "      <td>[-0.007179319, -0.017472098, 0.007090895, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jan 28, 2023\\n\\nA conversation with ChatGPT ab...</td>\n",
       "      <td>[-0.0044853278, -0.004643293, 0.009783447, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aug 28, 2021\\n\\nAnatomy of the Beast with many...</td>\n",
       "      <td>[-0.03625028, 0.002925193, -0.017852677, 0.058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2y\\n\\nProbabilistic Language Models\\n      \\n ...</td>\n",
       "      <td>[-0.0006725463, -0.013767892, -0.03115664, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1w\\n\\n7 Steps to Successful Network Optimizati...</td>\n",
       "      <td>[0.026594734, -0.029300328, -0.026127528, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2y\\n\\nDeep Learning for image search engines [...</td>\n",
       "      <td>[-0.010049002, -0.02393891, -0.030240124, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3y\\n\\nDeep Learning: Deep Dreaming\\n      \\n  ...</td>\n",
       "      <td>[-0.023225011, -0.024646016, -0.011872583, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Transformers without pain ü§ó\\n\\nReport this ...</td>\n",
       "      <td>[0.0010315055, -0.028580409, -0.0076014455, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Convolutional Neural Networks are trivial to p...</td>\n",
       "      <td>[-0.0009383782, -0.0289818, -0.023477007, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4) Architecture main components\\n\\nEncoder com...</td>\n",
       "      <td>[-0.020651396, -0.01635578, -0.024015633, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>An example fo using attention for machine tran...</td>\n",
       "      <td>[-0.0097579835, -0.008790414, -0.018799463, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Each word is projected into three other vector...</td>\n",
       "      <td>[-0.01479975, -0.025010662, -0.04422533, 0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>For example, a word w may attend to word x in ...</td>\n",
       "      <td>[-0.009083958, -0.02020066, -0.030411098, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>As shown, we have 3 connected arrows in the fi...</td>\n",
       "      <td>[-0.00903019, -0.008585256, -0.031742916, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Think of the positional encoders as a simple l...</td>\n",
       "      <td>[-0.015467625, -0.03785381, -0.04217757, 0.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8) The big picture\\n\\nAttention is all you nee...</td>\n",
       "      <td>[-0.018798167, -0.013468233, -0.01657415, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>For Example, \"Pre-training of Deep Bidirection...</td>\n",
       "      <td>[-0.002645978, -0.012628271, 0.0039097792, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Moreover, Transformers are recently used for c...</td>\n",
       "      <td>[0.0011646682, -0.01502404, 0.006865669, 0.048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Like\\n\\nLike\\n\\nCelebrate\\n\\nSupport\\n\\nLove\\n...</td>\n",
       "      <td>[-0.007179319, -0.017472098, 0.007090895, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jan 28, 2023\\n\\nA conversation with ChatGPT ab...</td>\n",
       "      <td>[-0.0044853278, -0.004643293, 0.009783447, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Aug 28, 2021\\n\\nAnatomy of the Beast with many...</td>\n",
       "      <td>[-0.03625028, 0.002925193, -0.017852677, 0.058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2y\\n\\nProbabilistic Language Models\\n      \\n ...</td>\n",
       "      <td>[-0.0006725463, -0.013767892, -0.03115664, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1w\\n\\n7 Steps to Successful Network Optimizati...</td>\n",
       "      <td>[0.026594734, -0.029300328, -0.026127528, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2y\\n\\nDeep Learning for image search engines [...</td>\n",
       "      <td>[-0.010049002, -0.02393891, -0.030240124, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3y\\n\\nDeep Learning: Deep Dreaming\\n      \\n  ...</td>\n",
       "      <td>[-0.023225011, -0.024646016, -0.011872583, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  \\\n",
       "0   Transformers without pain ü§ó\\n\\nReport this ...   \n",
       "1   Convolutional Neural Networks are trivial to p...   \n",
       "2   4) Architecture main components\\n\\nEncoder com...   \n",
       "3   An example fo using attention for machine tran...   \n",
       "4   Each word is projected into three other vector...   \n",
       "5   For example, a word w may attend to word x in ...   \n",
       "6   As shown, we have 3 connected arrows in the fi...   \n",
       "7   Think of the positional encoders as a simple l...   \n",
       "8   8) The big picture\\n\\nAttention is all you nee...   \n",
       "9   For Example, \"Pre-training of Deep Bidirection...   \n",
       "10  Moreover, Transformers are recently used for c...   \n",
       "11  Like\\n\\nLike\\n\\nCelebrate\\n\\nSupport\\n\\nLove\\n...   \n",
       "12  Jan 28, 2023\\n\\nA conversation with ChatGPT ab...   \n",
       "13  Aug 28, 2021\\n\\nAnatomy of the Beast with many...   \n",
       "14  2y\\n\\nProbabilistic Language Models\\n      \\n ...   \n",
       "15  1w\\n\\n7 Steps to Successful Network Optimizati...   \n",
       "16  2y\\n\\nDeep Learning for image search engines [...   \n",
       "17  3y\\n\\nDeep Learning: Deep Dreaming\\n      \\n  ...   \n",
       "18  Transformers without pain ü§ó\\n\\nReport this ...   \n",
       "19  Convolutional Neural Networks are trivial to p...   \n",
       "20  4) Architecture main components\\n\\nEncoder com...   \n",
       "21  An example fo using attention for machine tran...   \n",
       "22  Each word is projected into three other vector...   \n",
       "23  For example, a word w may attend to word x in ...   \n",
       "24  As shown, we have 3 connected arrows in the fi...   \n",
       "25  Think of the positional encoders as a simple l...   \n",
       "26  8) The big picture\\n\\nAttention is all you nee...   \n",
       "27  For Example, \"Pre-training of Deep Bidirection...   \n",
       "28  Moreover, Transformers are recently used for c...   \n",
       "29  Like\\n\\nLike\\n\\nCelebrate\\n\\nSupport\\n\\nLove\\n...   \n",
       "30  Jan 28, 2023\\n\\nA conversation with ChatGPT ab...   \n",
       "31  Aug 28, 2021\\n\\nAnatomy of the Beast with many...   \n",
       "32  2y\\n\\nProbabilistic Language Models\\n      \\n ...   \n",
       "33  1w\\n\\n7 Steps to Successful Network Optimizati...   \n",
       "34  2y\\n\\nDeep Learning for image search engines [...   \n",
       "35  3y\\n\\nDeep Learning: Deep Dreaming\\n      \\n  ...   \n",
       "\n",
       "                                           Embeddings  \n",
       "0   [0.0010315055, -0.028580409, -0.0076014455, 0....  \n",
       "1   [-0.0009383782, -0.0289818, -0.023477007, 0.04...  \n",
       "2   [-0.020651396, -0.01635578, -0.024015633, 0.05...  \n",
       "3   [-0.0097579835, -0.008790414, -0.018799463, 0....  \n",
       "4   [-0.01479975, -0.025010662, -0.04422533, 0.020...  \n",
       "5   [-0.009083958, -0.02020066, -0.030411098, 0.00...  \n",
       "6   [-0.00903019, -0.008585256, -0.031742916, 0.02...  \n",
       "7   [-0.015467625, -0.03785381, -0.04217757, 0.004...  \n",
       "8   [-0.018798167, -0.013468233, -0.01657415, 0.04...  \n",
       "9   [-0.002645978, -0.012628271, 0.0039097792, 0.0...  \n",
       "10  [0.0011646682, -0.01502404, 0.006865669, 0.048...  \n",
       "11  [-0.007179319, -0.017472098, 0.007090895, 0.04...  \n",
       "12  [-0.0044853278, -0.004643293, 0.009783447, 0.0...  \n",
       "13  [-0.03625028, 0.002925193, -0.017852677, 0.058...  \n",
       "14  [-0.0006725463, -0.013767892, -0.03115664, 0.0...  \n",
       "15  [0.026594734, -0.029300328, -0.026127528, 0.03...  \n",
       "16  [-0.010049002, -0.02393891, -0.030240124, 0.04...  \n",
       "17  [-0.023225011, -0.024646016, -0.011872583, 0.0...  \n",
       "18  [0.0010315055, -0.028580409, -0.0076014455, 0....  \n",
       "19  [-0.0009383782, -0.0289818, -0.023477007, 0.04...  \n",
       "20  [-0.020651396, -0.01635578, -0.024015633, 0.05...  \n",
       "21  [-0.0097579835, -0.008790414, -0.018799463, 0....  \n",
       "22  [-0.01479975, -0.025010662, -0.04422533, 0.020...  \n",
       "23  [-0.009083958, -0.02020066, -0.030411098, 0.00...  \n",
       "24  [-0.00903019, -0.008585256, -0.031742916, 0.02...  \n",
       "25  [-0.015467625, -0.03785381, -0.04217757, 0.004...  \n",
       "26  [-0.018798167, -0.013468233, -0.01657415, 0.04...  \n",
       "27  [-0.002645978, -0.012628271, 0.0039097792, 0.0...  \n",
       "28  [0.0011646682, -0.01502404, 0.006865669, 0.048...  \n",
       "29  [-0.007179319, -0.017472098, 0.007090895, 0.04...  \n",
       "30  [-0.0044853278, -0.004643293, 0.009783447, 0.0...  \n",
       "31  [-0.03625028, 0.002925193, -0.017852677, 0.058...  \n",
       "32  [-0.0006725463, -0.013767892, -0.03115664, 0.0...  \n",
       "33  [0.026594734, -0.029300328, -0.026127528, 0.03...  \n",
       "34  [-0.010049002, -0.02393891, -0.030240124, 0.04...  \n",
       "35  [-0.023225011, -0.024646016, -0.011872583, 0.0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine translation (MT) is the process of converting a text from one language to another. It is a subfield of computational linguistics, and has applications in many areas, such as translation of documents, websites, and software.\n",
      "\n",
      "There are two main types of machine translation systems: statistical and rule-based. Statistical MT systems use statistical techniques to learn the relationship between words and phrases in two languages, and then use this information to generate translations. Rule-based MT systems use a set of rules to translate text from one language to another.\n",
      "\n",
      "MT systems have improved significantly in recent years, but they still make mistakes. Some of the most common errors include:\n",
      "\n",
      "* Mistranslation of idioms and other figurative language\n",
      "* Mistranslation of proper nouns\n",
      "* Mistranslation of words with multiple meanings\n",
      "* Inaccurate translation of complex sentences\n",
      "\n",
      "Despite these limitations, MT systems are still very useful tools for translating text between languages. They are especially useful for translating large amounts of text, such as documents or websites.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "query = 'What is Machine Translation?'\n",
    "# change the Embeding column type to object \n",
    "# df['Embeddings'] = df['Embeddings'].astype(object)\n",
    "ans = text_generator.get_genrate_url_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
